# -*- coding: utf-8 -*-
"""SU-Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v0MozyDf9d12qNF5_xy8m7wvyY1B836N
"""

import os
import zipfile
import requests
from tqdm import tqdm
import shutil

# Base directory
BASE_DIR = "/content/data"
os.makedirs(BASE_DIR, exist_ok=True)

# RAVDESS dataset URL only
RAVDESS_URL = "https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip"

# Download + extract function
def download_and_extract(dataset_name, url):
    dataset_path = os.path.join(BASE_DIR, dataset_name)
    os.makedirs(dataset_path, exist_ok=True)

    zip_path = os.path.join(dataset_path, f"{dataset_name}.zip")

    print(f"ðŸ“¥ Downloading {dataset_name}...")
    r = requests.get(url, stream=True)
    total_size = int(r.headers.get('content-length', 0))

    with open(zip_path, 'wb') as f, tqdm(
        desc=f"{dataset_name}.zip",
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024
    ) as bar:
        for chunk in r.iter_content(chunk_size=1024):
            bar.update(len(chunk))
            f.write(chunk)

    print(f"ðŸ“¦ Extracting {dataset_name}...")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(dataset_path)
    os.remove(zip_path)
    print(f"âœ… {dataset_name} ready!\n")

# Download and extract only RAVDESS
download_and_extract("ravdess", RAVDESS_URL)

from google.colab import files
files.upload()  # Prompt to upload the kaggle.json file

# 2. Create the kaggle directory
!mkdir -p ~/.kaggle

# 3. Move the uploaded file into that directory
!mv kaggle.json ~/.kaggle/

# 4. Set permissions so it works securely
!chmod 600 ~/.kaggle/kaggle.json

# Create a folder to store TESS
!mkdir -p /content/data/tess

# Download TESS dataset using Kaggle API
!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess -p /content/data/tess

# Extract the dataset
import zipfile

with zipfile.ZipFile('/content/data/tess/toronto-emotional-speech-set-tess.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/data/tess')

# Optionally remove the ZIP to save space
!rm /content/data/tess/toronto-emotional-speech-set-tess.zip

# Create a directory for CREMA-D
!mkdir -p /content/data/crema-d

# Download the dataset
!kaggle datasets download -d ejlok1/cremad -p /content/data/crema-d

# Extract the contents
import zipfile

with zipfile.ZipFile('/content/data/crema-d/cremad.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/data/crema-d')

# Clean up ZIP to save space
!rm /content/data/crema-d/cremad.zip

import os
import shutil

# Emotion mapping based on codes in file/folder names
crema_map = {
    'ANG': 'angry', 'DIS': 'disgust', 'FEA': 'fear',
    'HAP': 'happy', 'NEU': 'neutral', 'SAD': 'sad'
}
ravdess_map = {
    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',
    '05': 'angry', '06': 'fear', '07': 'disgust', '08': 'surprise'
}
# TESS emotions are directly in folder names

# Final target directory
FINAL_DIR = "/content/data/final"
os.makedirs(FINAL_DIR, exist_ok=True)

def copy_to_emotion_folder(src, emotion, prefix):
    if emotion not in ['happy', 'sad', 'angry', 'fear', 'neutral', 'disgust', 'surprise']:
        return
    tgt_dir = os.path.join(FINAL_DIR, emotion)
    os.makedirs(tgt_dir, exist_ok=True)
    dst = os.path.join(tgt_dir, f"{prefix}_{os.path.basename(src)}")
    shutil.copy(src, dst)

# ============ RAVDESS ============
print("Organizing RAVDESS...")
ravdess_root = "/content/data/ravdess/Audio_Speech_Actors_01-24"
for root, _, files in os.walk(ravdess_root):
    for file in files:
        if file.endswith(".wav"):
            emotion_code = file.split("-")[2]
            emotion = ravdess_map.get(emotion_code)
            if emotion:
                src = os.path.join(root, file)
                copy_to_emotion_folder(src, emotion, "ravdess")

# ============ CREMA-D ============
print("Organizing CREMA-D...")
crema_root = "/content/data/crema-d/AudioWAV"
for file in os.listdir(crema_root):
    if file.endswith(".wav"):
        emotion_code = file.split("_")[2]
        emotion = crema_map.get(emotion_code)
        if emotion:
            src = os.path.join(crema_root, file)
            copy_to_emotion_folder(src, emotion, "crema")

# ============ TESS ============
print("Organizing TESS...")
tess_root = "/content/data/tess/TESS Toronto emotional speech set data"
for folder in os.listdir(tess_root):
    folder_path = os.path.join(tess_root, folder)
    for file in os.listdir(folder_path):
        if file.endswith(".wav"):
            for emotion in ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']:
                if emotion.upper() in file:
                    src = os.path.join(folder_path, file)
                    copy_to_emotion_folder(src, emotion, "tess")

print("âœ… All datasets are now merged and organized under /content/data/final/<emotion>")

import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import seaborn as sns
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense
from keras.optimizers import Adam

"""# =====================================
# PHASE 1: Emotion Detection Model (CNN)
# =====================================
"""

# Emotion classes (based on existing folders)
emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad']

# Load data
DATA_PATH = "/content/data/final"

emotion_to_index = {e: i for i, e in enumerate(emotion_labels)}

X, y = [], []

for emotion in emotion_labels:
    emotion_folder = os.path.join(DATA_PATH, emotion)
    for file in os.listdir(emotion_folder):
        if file.endswith(".wav"):
            file_path = os.path.join(emotion_folder, file)
            y_raw, sr = librosa.load(file_path, duration=3, offset=0.5)
            mfcc = librosa.feature.mfcc(y=y_raw, sr=sr, n_mfcc=40)
            if mfcc.shape[1] < 174:
                pad_width = 174 - mfcc.shape[1]
                mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)))
            else:
                mfcc = mfcc[:, :174]
            X.append(mfcc)
            y.append(emotion_to_index[emotion])

X = np.array(X)
y = np.array(y)
y_cat = to_categorical(y, num_classes=len(emotion_labels))
X = X[..., np.newaxis]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

# CNN model for emotion recognition
model_emotion = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(40,174,1)),
    MaxPooling2D((2,2)),
    Dropout(0.3),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Dropout(0.3),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(len(emotion_labels), activation='softmax')
])

model_emotion.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
model_emotion.summary()

history = model_emotion.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# Evaluation
loss, acc = model_emotion.evaluate(X_test, y_test)
print(f"\nEmotion Detection Accuracy: {acc * 100:.2f}%")

# Confusion Matrix and F1-Score for emotions
y_true_emotion = np.argmax(y_test, axis=1)
y_pred_emotion = np.argmax(model_emotion.predict(X_test), axis=1)
cm_emotion = confusion_matrix(y_true_emotion, y_pred_emotion)
sns.heatmap(cm_emotion, annot=True, fmt='d', xticklabels=emotion_labels, yticklabels=emotion_labels)
plt.title("Confusion Matrix - Emotion Detection")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

print("\nClassification Report (Emotion Detection):")
print(classification_report(y_true_emotion, y_pred_emotion, target_names=emotion_labels))

# Save model
model_emotion.save("emotion_model.h5")

"""# =====================================
# PHASE 2: Sentiment Mapping
# =====================================
"""

print("=============================")
print("       PHASE 2: SENTIMENT MAPPING")
print("=============================")

# Map emotions to sentiments
emotion_to_sentiment = {
    'happy': 'positive',
    'neutral': 'neutral',
    'sad': 'negative',
    'angry': 'negative',
    'fear': 'negative',
    'disgust': 'negative'
}
sentiment_labels = ['positive', 'neutral', 'negative']
sentiment_to_index = {s: i for i, s in enumerate(sentiment_labels)}

X_sentiment, y_sentiment = [], []

for emotion in emotion_labels:
    sentiment = emotion_to_sentiment[emotion]
    sentiment_index = sentiment_to_index[sentiment]
    emotion_folder = os.path.join(DATA_PATH, emotion)
    for file in os.listdir(emotion_folder):
        if file.endswith(".wav"):
            file_path = os.path.join(emotion_folder, file)
            y_raw, sr = librosa.load(file_path, duration=3, offset=0.5)
            mfcc = librosa.feature.mfcc(y=y_raw, sr=sr, n_mfcc=40)
            if mfcc.shape[1] < 174:
                pad_width = 174 - mfcc.shape[1]
                mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)))
            else:
                mfcc = mfcc[:, :174]
            X_sentiment.append(mfcc)
            y_sentiment.append(sentiment_index)

X_sentiment = np.array(X_sentiment)[..., np.newaxis]
y_sentiment = np.array(y_sentiment)
y_sent_cat = to_categorical(y_sentiment, num_classes=3)

X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sentiment, y_sent_cat, test_size=0.2, random_state=42)

# CNN model for sentiment classification
model_sentiment = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(40,174,1)),
    MaxPooling2D((2,2)),
    Dropout(0.3),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Dropout(0.3),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')
])

model_sentiment.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
model_sentiment.summary()

model_sentiment.fit(X_train_s, y_train_s, epochs=20, batch_size=32, validation_data=(X_test_s, y_test_s))

# Evaluation
loss_s, acc_s = model_sentiment.evaluate(X_test_s, y_test_s)
print(f"\nSentiment Classification Accuracy: {acc_s * 100:.2f}%")

# Confusion Matrix and F1-Score for sentiment classification
y_true_sent = np.argmax(y_test_s, axis=1)
y_pred_sent = np.argmax(model_sentiment.predict(X_test_s), axis=1)
cm_sentiment = confusion_matrix(y_true_sent, y_pred_sent)
sns.heatmap(cm_sentiment, annot=True, fmt='d', xticklabels=sentiment_labels, yticklabels=sentiment_labels)
plt.title("Confusion Matrix - Sentiment Classification")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

print("\nClassification Report (Sentiment Classification):")
print(classification_report(y_true_sent, y_pred_sent, target_names=sentiment_labels))

# Save model
model_sentiment.save("sentiment_model.h5")